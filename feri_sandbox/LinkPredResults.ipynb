{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from datawand.parametrization import ParamHelper\n",
    "ph = ParamHelper('..', 'LinkPrediction', sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_df = pd.read_csv(\"/mnt/idms/fberes/data/bitcoin_ln_research/link_prediction/data/links_df_20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 20#None#30#ph.get(\"top_first_days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K == None:\n",
    "    delta_t = 86400*7\n",
    "else:\n",
    "    delta_t = 86400#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"onmf_dim10_lr0.140_nr100\",\n",
    "    \"bomf_dim10_lr0.140_nr100\",\n",
    "    \"offmf_dim10_lr0.050_nr100\",\n",
    "    \"pop\",\n",
    "    \"time_pop\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_dir = \"/mnt/idms/fberes/data/bitcoin_ln_research/link_prediction/rankings/topk20_exkTrue_%s/\" % str(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings = [pd.read_csv(\"%s/%s.csv\" % (ranking_dir,m)) for m in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(df) for df in rankings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings[0]['time'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TIME = 1548982800 # (GMT): Friday, February 1, 2019 1:00:00 AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timeframe(df, delta_t, min_time=1548982800):\n",
    "    df[\"timeframe\"] = df[\"time\"].apply(lambda x: max(0,(x-min_time)//delta_t))\n",
    "\n",
    "for i in range(len(rankings)):\n",
    "    get_timeframe(rankings[i], delta_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings[4].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.) average performance (online DCG)\n",
    "\n",
    "The average performance for the offline batch model is confusing (it is only bad on the first day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mean_dcg(with_first_day=True):\n",
    "    if with_first_day:\n",
    "        mean_dcgs = [df[\"dcg\"].mean() for df in rankings]\n",
    "        df = rankings[0]\n",
    "        print(len(df))\n",
    "    else:\n",
    "        mean_dcgs = [df[df[\"timeframe\"]>0][\"dcg\"].mean() for df in rankings]\n",
    "        df = rankings[0]\n",
    "        print(len(df[df[\"timeframe\"]>0]))\n",
    "    return pd.DataFrame(list(zip(models, mean_dcgs)), columns=[\"model\",\"dcg\"]).sort_values(\"dcg\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global mean performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_mean_dcg(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean performance without first day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_mean_dcg(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exclude known: False**\n",
    "0 \tonline \t0.139660\n",
    "1 \tbatch+online \t0.131745\n",
    "2 \tpop+time \t0.124183\n",
    "3 \tpop \t0.077110\n",
    "4 \tbatch \t0.064587\n",
    "\n",
    "**Exclude known: True - Mi\u00e9rt teljesen uaz?**\n",
    "0 \tonline \t0.139660\n",
    "1 \tbatch+online \t0.131745\n",
    "2 \tpop+time \t0.124183\n",
    "3 \tpop \t0.077110\n",
    "4 \tbatch \t0.064587"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.) Performance over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, ranking in enumerate(rankings):\n",
    "    averages = ranking.groupby(\"timeframe\")[\"dcg\"].mean()\n",
    "    plt.plot(averages, label=models[idx])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.) Number of records over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = rankings[0].groupby(\"timeframe\")[\"dcg\"].count()\n",
    "plt.plot(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation based results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "experiment_id = \"200000sat_k10000_aNone_e0.05_dropTrue-onmf_dim10_lr0.140_nr100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpenglow.evaluation import DcgScore\n",
    "\n",
    "def load_link_sim_experiment(model_dir):\n",
    "    model_id = model_dir.split(\"/\")[-2]\n",
    "    print(model_id)\n",
    "    model_files = os.listdir(model_dir)\n",
    "    chunks = [pd.read_csv(\"%s/%s\" % (model_dir, f)) for f in model_files]\n",
    "    concatenated = pd.concat(chunks)\n",
    "    print(len(model_files), len(concatenated))\n",
    "    get_timeframe(concatenated, delta_t)\n",
    "    #print(concatenated.isnull().sum() / len(concatenated))\n",
    "    concatenated[model_id] = DcgScore(concatenated)\n",
    "    print(concatenated[model_id].mean())\n",
    "    concatenated['base_dcg'] = DcgScore(concatenated.drop(\"rank\",axis=1).rename({\"base\":\"rank\"}, axis=1))\n",
    "    print(concatenated[\"base_dcg\"].mean())\n",
    "    return concatenated.drop(\"base_dcg\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    \"200000sat_k10000_aNone_e0.05_dropTrue-onmf_dim10_lr0.140_nr100\",\n",
    "    \"200000sat_k10000_aNone_e0.05_dropFalse-onmf_dim10_lr0.140_nr100\",\n",
    "    \"200000sat_k10000_a2.0_e0.05_dropTrue-onmf_dim10_lr0.140_nr100\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_results = [load_link_sim_experiment(\"%s/%s/\" % (ranking_dir, experiment_id)) for experiment_id in experiments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_preds = simulation_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, model in enumerate(experiments[1:]):\n",
    "    sim_preds = sim_preds.merge(simulation_results[idx+1][[\"record_id\",model]], on=\"record_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining baselines with simulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, model in enumerate(models):\n",
    "    sim_preds = sim_preds.merge(rankings[idx][[\"id\",\"dcg\"]].rename({\"id\":\"record_id\",\"dcg\":model}, axis=1), on=\"record_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_preds[experiments+models].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K=20\n",
    "\n",
    "- onmf_dim10_lr0.140_nr100     0.166119\n",
    "- base_dcg                     0.166119\n",
    "- bomf_dim10_lr0.140_nr100     0.155521\n",
    "- dcg (drop disabled True)     0.140450\n",
    "- time_pop                     0.131762\n",
    "- pop                          0.076994\n",
    "- offmf_dim10_lr0.050_nr100    0.076188"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [\"onmf_dim10_lr0.140_nr100\",\"time_pop\",\"200000sat_k10000_aNone_e0.05_dropTrue-onmf_dim10_lr0.140_nr100\"]:\n",
    "    averages = sim_preds.groupby(\"timeframe\")[model].mean()\n",
    "    plt.plot(averages, label=model)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(sim_preds[\"dcg\"] > sim_preds[\"base_dcg\"]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sim_is_better = sim_preds[sim_preds[\"dcg\"] > sim_preds[\"base_dcg\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mf_is_better = sim_preds[sim_preds[\"dcg\"] < sim_preds[\"base_dcg\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sim_is_better[\"snapshot\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(sim_is_better[\"dcg\"] - sim_is_better[\"base_dcg\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(mf_is_better[\"dcg\"] - mf_is_better[\"base_dcg\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sim is better top10\n",
    "\n",
    "- LNBIG.com [lnd-06]\n",
    "- LNBIG.com [lnd-32]\n",
    "- LNBIG.com [lnd-05]\n",
    "- LNBIG.com [lnd-28/old-lnd-22]\n",
    "- LNBIG.com [lnd-26]\n",
    "- LNBIG.com [lnd-27/old-lnd-19]\n",
    "- LNBIG.com [lnd-17]\n",
    "- LNBIG.com [lnd-07]\n",
    "- LNBIG.com [lnd-21]\n",
    "- LNBIG.com [lnd-33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sim_is_better[\"src\"].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MF is better top10\n",
    "\n",
    "- LNBIG.com [lnd-17]\n",
    "- LNBIG.com [lnd-32]\n",
    "- LNBIG.com [lnd-27/old-lnd-19]\n",
    "- LNBIG.com [lnd-33]\n",
    "- ... all is LNBIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mf_is_better[\"src\"].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sim_preds.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sim_preds.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sim_preds[\"diff\"] = sim_preds[\"dcg\"] - sim_preds[\"base_dcg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean_diff = sim_preds.groupby(\"src\")[\"diff\"].mean().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MF is much better in average\n",
    "\n",
    "- MJOLNIR\n",
    "- DMN737\n",
    "- just a hash\n",
    "- sqlserver.science\n",
    "- Ziggy [LND]\n",
    "\n",
    "They have just a few dollards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean_diff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean_diff.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightningPowerUsers.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean_diff[\"0331f80652fb840239df8dc99205792bba2e559a05469915804c08420230e23c7c\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACINQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean_diff[\"03864ef025fde8fb587d989186ce6a4a186895ee44a926bfc370e2c366597a3f8f\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dm-3-env] *",
   "language": "python",
   "name": "conda-env-dm-3-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}